{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General information\n",
    "\n",
    "This kernel is created using data of `Predicting Molecular Properties` competition.\n",
    "We have information about atom couples in molecules and need to predict `scalar_coupling_constant` between these atoms.\n",
    "\n",
    "![](http://www.et.byu.edu/~rowley/VLEfinal/methane_dimer.gif)\n",
    "\n",
    "In this kernel I'll do EDA and will try some approaches to modelling.\n",
    "\n",
    "*Work still in progress*\n",
    "\n",
    "\n",
    "~Thanks to the new kaggle update we can write code in kernels and import it. This is much more convenient and useful. I'm moving all the functions I can into this script: https://www.kaggle.com/artgor/artgor-utils So if you see somewhere code like artgot_utils.function_name(parameters) - it is from this script~\n",
    "I have realized that using utility scripts isn't very convenient, so I move all the code from that script into the notebook. But "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Edir\\\\Source\\\\Repos\\\\kaggle\\\\champs-scalar-coupling',\n",
       " 'D:\\\\repos\\\\models\\\\research',\n",
       " 'C:\\\\Users\\\\Edir\\\\Anaconda3\\\\python36.zip',\n",
       " 'C:\\\\Users\\\\Edir\\\\Anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\Edir\\\\Anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\Edir\\\\Anaconda3',\n",
       " 'C:\\\\Users\\\\Edir\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'd:\\\\repos\\\\models\\\\research\\\\slim',\n",
       " 'd:\\\\repos\\\\models\\\\research\\\\delf',\n",
       " 'C:\\\\Users\\\\Edir\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\Edir\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\Edir\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\Edir\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\Edir\\\\.ipython']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "current_path = !cd\n",
    "current_path[0]\n",
    "\n",
    "if not current_path[0] in sys.path:\n",
    "    sys.path.insert(0, current_path[0])\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Edir\\\\Anaconda3'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>    requirejs.config({\n",
       "        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n",
       "        paths: {'vega': 'https://cdn.jsdelivr.net/npm/vega@v3.3.1?noext', 'vega-lib': 'https://cdn.jsdelivr.net/npm/vega-lib?noext', 'vega-lite': 'https://cdn.jsdelivr.net/npm/vega-lite@v3.2.1?noext', 'vega-embed': 'https://cdn.jsdelivr.net/npm/vega-embed@3?noext'}\n",
       "    });\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "\n",
    "import lightgbm as lgb\n",
    "#import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "#from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "import altair as alt\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "alt.renderers.enable('notebook')\n",
    "import artgor_utils\n",
    "\n",
    "# setting up altair\n",
    "workaround = artgor_utils.prepare_altair()\n",
    "HTML(\"\".join((\n",
    "    \"<script>\",\n",
    "    workaround,\n",
    "    \"</script>\",\n",
    ")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input/champs-scalar-coupling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-997e98462086>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/champs-scalar-coupling'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input/champs-scalar-coupling'"
     ]
    }
   ],
   "source": [
    "os.listdir('../input/champs-scalar-coupling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of files, let's focus on the main ones for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/champs-scalar-coupling/train.csv')\n",
    "test = pd.read_csv('../input/champs-scalar-coupling/test.csv')\n",
    "sub = pd.read_csv('../input/champs-scalar-coupling/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {train.shape[0]} rows in train data.')\n",
    "print(f'There are {test.shape[0]} rows in test data.')\n",
    "\n",
    "print(f\"There are {train['molecule_name'].nunique()} distinct molecules in train data.\")\n",
    "print(f\"There are {test['molecule_name'].nunique()} distinct molecules in test data.\")\n",
    "print(f\"There are {train['atom_index_0'].nunique()} unique atoms.\")\n",
    "print(f\"There are {train['type'].nunique()} unique types.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in out main data files we have information about moleculas and pairs of atoms\n",
    "- test set in ~2 times smaller that train set;\n",
    "- we have 28 unique atoms types and 8 coupling types;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "atom_count = train['atom_index_0'].value_counts().reset_index().rename(columns={'atom_index_0': 'count', 'index': 'atom_index_0'})\n",
    "chart1 = alt.Chart(atom_count).mark_bar().encode(\n",
    "    x=alt.X(\"atom_index_0:N\", axis=alt.Axis(title='atom_index_0')),\n",
    "    y=alt.Y('count:Q', axis=alt.Axis(title='Count')),\n",
    "    tooltip=['atom_index_0', 'count']\n",
    ").properties(title=\"Counts of atom_index_0\", width=350).interactive()\n",
    "\n",
    "atom_count = train['atom_index_1'].value_counts().reset_index().rename(columns={'atom_index_1': 'count', 'index': 'atom_index_1'})\n",
    "chart2 = alt.Chart(atom_count).mark_bar().encode(\n",
    "    x=alt.X(\"atom_index_1:N\", axis=alt.Axis(title='atom_index_1')),\n",
    "    y=alt.Y('count:Q', axis=alt.Axis(title='Count')),\n",
    "    tooltip=['atom_index_1', 'count']\n",
    ").properties(title=\"Counts of atom_index_1\", width=350).interactive()\n",
    "\n",
    "type_count = train['type'].value_counts().reset_index().rename(columns={'type': 'count', 'index': 'type'})\n",
    "chart3 = alt.Chart(type_count).mark_bar().encode(\n",
    "    x=alt.X(\"type:N\", axis=alt.Axis(title='type')),\n",
    "    y=alt.Y('count:Q', axis=alt.Axis(title='Count')),\n",
    "    tooltip=['type', 'count']\n",
    ").properties(title=\"Counts of type\", width=350).interactive()\n",
    "\n",
    "hist_df = pd.cut(train['scalar_coupling_constant'], 20).value_counts().sort_index().reset_index().rename(columns={'index': 'bins'})\n",
    "hist_df['bins'] = hist_df['bins'].astype(str)\n",
    "chart4 = alt.Chart(hist_df).mark_bar().encode(\n",
    "    x=alt.X(\"bins:O\", axis=alt.Axis(title='Target bins')),\n",
    "    y=alt.Y('scalar_coupling_constant:Q', axis=alt.Axis(title='Count')),\n",
    "    tooltip=['scalar_coupling_constant', 'bins']\n",
    ").properties(title=\"scalar_coupling_constant histogram\", width=400).interactive()\n",
    "\n",
    "\n",
    "(chart1 | chart2) & (chart3 | chart4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (18, 6))\n",
    "plt.subplot(1, 2, 1);\n",
    "plt.hist(train['scalar_coupling_constant'], bins=20);\n",
    "plt.title('Basic scalar_coupling_constant histogram');\n",
    "plt.subplot(1, 2, 2);\n",
    "sns.violinplot(x='type', y='scalar_coupling_constant', data=train);\n",
    "plt.title('Violinplot of scalar_coupling_constant by type');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many interesting things here:\n",
    "- among first atoms there is a little number of atoms with index lower than 7 or higher than 24;\n",
    "- among second atoms there is a little number of atoms with index higher than 24. Also index with atom with index 9 in quite rare;\n",
    "- coupling types are unevenly distributed. There are 3 very popular, 3 quite rare and 2 with medium frequency;\n",
    "- target variable has a bimodal distribution;\n",
    "- different coupling types have really different values of target variable. Maybe it would make sense to build separate models for each of them;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting network graphs by type\n",
    "\n",
    "We have molecules, atom pairs, so this means data, which is interconnected. Network graphs should be useful to visualize such data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20, 12))\n",
    "for i, t in enumerate(train['type'].unique()):\n",
    "    train_type = train.loc[train['type'] == t]\n",
    "    G = nx.from_pandas_edgelist(train_type, 'atom_index_0', 'atom_index_1', ['scalar_coupling_constant'])\n",
    "    plt.subplot(2, 4, i + 1);\n",
    "    nx.draw(G, with_labels=True);\n",
    "    plt.title(f'Graph for type {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We can see that atom connections have different shapes for different types. Type 2JHH has an expecially unique scheme.\n",
    "Also we can see that some atoms are connected only to several other atoms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better network graphs\n",
    "But there is a little problem: as we saw earlier, there are atoms which are very rare, as a result graphs will be skewed due to them. Now I'll drop atoms for each type which are present in less then 1% of connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20, 12))\n",
    "for i, t in enumerate(train['type'].unique()):\n",
    "    train_type = train.loc[train['type'] == t]\n",
    "    bad_atoms_0 = list(train_type['atom_index_0'].value_counts(normalize=True)[train_type['atom_index_0'].value_counts(normalize=True) < 0.01].index)\n",
    "    bad_atoms_1 = list(train_type['atom_index_1'].value_counts(normalize=True)[train_type['atom_index_1'].value_counts(normalize=True) < 0.01].index)\n",
    "    bad_atoms = list(set(bad_atoms_0 + bad_atoms_1))\n",
    "    train_type = train_type.loc[(train_type['atom_index_0'].isin(bad_atoms_0) == False) & (train_type['atom_index_1'].isin(bad_atoms_0) == False)]\n",
    "    G = nx.from_pandas_edgelist(train_type, 'atom_index_0', 'atom_index_1', ['scalar_coupling_constant'])\n",
    "    plt.subplot(2, 4, i + 1);\n",
    "    nx.draw(G, with_labels=True);\n",
    "    plt.title(f'Graph for type {t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the graphs are much more clear!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "\n",
    "For now I'll use a basic approach to feature engineering.\n",
    "\n",
    "I'll use this useful kernel:\n",
    "https://www.kaggle.com/seriousran/just-speed-up-calculate-distance-from-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = pd.read_csv('../input/champs-scalar-coupling/structures.csv')\n",
    "\n",
    "def map_atom_info(df, atom_idx):\n",
    "    df = pd.merge(df, structures, how = 'left',\n",
    "                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_name',  'atom_index'])\n",
    "    \n",
    "    df = df.drop('atom_index', axis=1)\n",
    "    df = df.rename(columns={'atom': f'atom_{atom_idx}',\n",
    "                            'x': f'x_{atom_idx}',\n",
    "                            'y': f'y_{atom_idx}',\n",
    "                            'z': f'z_{atom_idx}'})\n",
    "    return df\n",
    "\n",
    "train = map_atom_info(train, 0)\n",
    "train = map_atom_info(train, 1)\n",
    "\n",
    "test = map_atom_info(test, 0)\n",
    "test = map_atom_info(test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p_0 = train[['x_0', 'y_0', 'z_0']].values\n",
    "train_p_1 = train[['x_1', 'y_1', 'z_1']].values\n",
    "test_p_0 = test[['x_0', 'y_0', 'z_0']].values\n",
    "test_p_1 = test[['x_1', 'y_1', 'z_1']].values\n",
    "\n",
    "train['dist'] = np.linalg.norm(train_p_0 - train_p_1, axis=1)\n",
    "test['dist'] = np.linalg.norm(test_p_0 - test_p_1, axis=1)\n",
    "train['dist_x'] = (train['x_0'] - train['x_1']) ** 2\n",
    "test['dist_x'] = (test['x_0'] - test['x_1']) ** 2\n",
    "train['dist_y'] = (train['y_0'] - train['y_1']) ** 2\n",
    "test['dist_y'] = (test['y_0'] - test['y_1']) ** 2\n",
    "train['dist_z'] = (train['z_0'] - train['z_1']) ** 2\n",
    "test['dist_z'] = (test['z_0'] - test['z_1']) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to create two new features: one will show the first character of the `type`, the second one will show other characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['type_0'] = train['type'].apply(lambda x: x[0])\n",
    "test['type_0'] = test['type'].apply(lambda x: x[0])\n",
    "train['type_1'] = train['type'].apply(lambda x: x[1:])\n",
    "test['type_1'] = test['type'].apply(lambda x: x[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, everyone uses this distance feature, let's have a look at it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (18, 8))\n",
    "plt.subplot(1, 2, 1);\n",
    "plt.hist(train['dist'], bins=20);\n",
    "plt.title('Basic dist_speedup histogram');\n",
    "plt.subplot(1, 2, 2);\n",
    "sns.violinplot(x='type', y='dist', data=train);\n",
    "plt.title('Violinplot of dist_speedup by type');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the values are quite different for different types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dist_to_type_mean'] = train['dist'] / train.groupby('type')['dist'].transform('mean')\n",
    "test['dist_to_type_mean'] = test['dist'] / test.groupby('type')['dist'].transform('mean')\n",
    "\n",
    "train['dist_to_type_0_mean'] = train['dist'] / train.groupby('type_0')['dist'].transform('mean')\n",
    "test['dist_to_type_0_mean'] = test['dist'] / test.groupby('type_0')['dist'].transform('mean')\n",
    "\n",
    "train['dist_to_type_1_mean'] = train['dist'] / train.groupby('type_1')['dist'].transform('mean')\n",
    "test['dist_to_type_1_mean'] = test['dist'] / test.groupby('type_1')['dist'].transform('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic model\n",
    "\n",
    "I'll use the function for metric calculation from this kernel: https://www.kaggle.com/abhishek/competition-metric\n",
    "\n",
    "UPD: use faster metric from this kernel: https://www.kaggle.com/uberkinder/efficient-metric\n",
    "\n",
    "You can see the code in my utility script. Please note that to use this metric for calculation you need to pass value `group_mae` to parameter `eval_metric`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.concat([train, pd.get_dummies(train['type'])], axis=1)\n",
    "# test = pd.concat([test, pd.get_dummies(test['type'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in ['atom_0', 'atom_1', 'type_0', 'type_1', 'type']:\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "    train[f] = lbl.transform(list(train[f].values))\n",
    "    test[f] = lbl.transform(list(test[f].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['id', 'molecule_name', 'scalar_coupling_constant'], axis=1)\n",
    "y = train['scalar_coupling_constant']\n",
    "X_test = test.drop(['id', 'molecule_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 128,\n",
    "          'min_child_samples': 79,\n",
    "          'objective': 'regression',\n",
    "          'max_depth': 9,\n",
    "          'learning_rate': 0.2,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"subsample_freq\": 1,\n",
    "          \"subsample\": 0.9,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.1,\n",
    "          'reg_lambda': 0.3,\n",
    "          'colsample_bytree': 1.0\n",
    "         }\n",
    "result_dict_lgb = artgor_utils.train_model_regression(X=X, X_test=X_test, y=y, params=params, folds=folds, model_type='lgb', eval_metric='group_mae', plot_feature_importance=True,\n",
    "                                                      verbose=1000, early_stopping_rounds=200, n_estimators=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['scalar_coupling_constant'] = result_dict_lgb['prediction']\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(result_dict_lgb['prediction'], bins=40);\n",
    "plt.title('Distribution of predictions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot oof predictions vs target\n",
    "\n",
    "I use the code from benchmark kernel: https://www.kaggle.com/inversion/atomic-distance-benchmark\n",
    "\n",
    "Notice that while using `LabelEncoder` on categorical variables, `type` was the last feature, so `lbl` contains encodings for it and we can inverse_transform `type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = pd.DataFrame(y)\n",
    "plot_data.index.name = 'id'\n",
    "plot_data['yhat'] = result_dict_lgb['oof']\n",
    "plot_data['type'] = lbl.inverse_transform(X['type'])\n",
    "\n",
    "def plot_oof_preds(ctype, llim, ulim):\n",
    "        plt.figure(figsize=(6,6))\n",
    "        sns.scatterplot(x='scalar_coupling_constant',y='yhat',\n",
    "                        data=plot_data.loc[plot_data['type']==ctype,\n",
    "                        ['scalar_coupling_constant', 'yhat']]);\n",
    "        plt.xlim((llim, ulim))\n",
    "        plt.ylim((llim, ulim))\n",
    "        plt.plot([llim, ulim], [llim, ulim])\n",
    "        plt.xlabel('scalar_coupling_constant')\n",
    "        plt.ylabel('predicted')\n",
    "        plt.title(f'{ctype}', fontsize=18)\n",
    "        plt.show()\n",
    "\n",
    "plot_oof_preds('1JHC', 0, 250)\n",
    "plot_oof_preds('1JHN', 0, 100)\n",
    "plot_oof_preds('2JHC', -50, 50)\n",
    "plot_oof_preds('2JHH', -50, 50)\n",
    "plot_oof_preds('2JHN', -25, 25)\n",
    "plot_oof_preds('3JHC', -25, 100)\n",
    "plot_oof_preds('3JHH', -20, 20)\n",
    "plot_oof_preds('3JHN', -15, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some types has better predictions than others. Maybe we should focus on improving models for these types?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
